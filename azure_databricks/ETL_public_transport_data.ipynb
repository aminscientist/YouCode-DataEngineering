{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "752d8845-7cbb-4f6d-bea5-2e3f04d56704",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Connection configuration\n",
    "spark.conf.set(\n",
    "\"fs.azure.account.key.aminbenstorage.blob.core.windows.net\", \"AQbPX3InwH459QioNrh/D0zeeCwhM0gACyGIfFC9UEJtJSJAe77zjhrtP2MXJe/DtCcvTfLVF5z/+AStd4j9Cg==\"\n",
    ")\n",
    "\n",
    "#affichage de données\n",
    "spark_df = spark.read.format('csv').option('header', True).load(\"wasbs://public-transport-data@aminbenstorage.blob.core.windows.net/raw/public-transport-data.csv\")\n",
    "\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a0ca201-c451-4242-9f75-6cc5d60b1af4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#infos sur les colonnes\n",
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4a24fc1-5d96-417f-9f52-f5a0f641310e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_dates = spark_df.select(\"Date\").distinct()\n",
    "display(unique_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc21430-c8c7-4400-9429-f7f5af86dc9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, dayofweek, to_date\n",
    "\n",
    "# Convertir la colonne \"Date\" en un format de date\n",
    "spark_df = spark_df.withColumn(\"Date\", to_date(\"Date\", \"yyyy-MM-dd\"))\n",
    "\n",
    "# Extraire l'année, le mois, le jour et le jour de la semaine\n",
    "spark_df = spark_df.withColumn(\"Year\", year(\"Date\"))\n",
    "spark_df = spark_df.withColumn(\"Month\", month(\"Date\"))\n",
    "spark_df = spark_df.withColumn(\"Day\", dayofmonth(\"Date\"))\n",
    "spark_df = spark_df.withColumn(\"DayOfWeek\", dayofweek(\"Date\"))\n",
    "\n",
    "# Afficher les résultats\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbcd678a-2c49-4e3b-96dc-bca700fc8a43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Supprimer les lignes où les deux premiers caractères de la colonne \"ArrivalTime\" sont \"24\" ou supérieurs à \"24\"\n",
    "spark_df = spark_df.filter(~(col(\"ArrivalTime\").substr(1, 2) >= \"24\"))\n",
    "spark_df = spark_df.filter(~(col(\"DepartureTime\").substr(1, 2) >= \"24\"))\n",
    "\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9d1b775-2af4-46f7-8c12-4c02b5c7b21a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, unix_timestamp \n",
    "spark_df = spark_df.withColumn(\"Duration\", expr(\n",
    "    \"from_unixtime(unix_timestamp(ArrivalTime, 'HH:mm') - unix_timestamp(DepartureTime, 'HH:mm'), 'HH:mm')\"\n",
    "))\n",
    "\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba6adb1-71a3-4310-9901-9c7f3fac5ab1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when \n",
    "\n",
    "# Catégoriser les retards en fonction de la colonne \"Delay\"\n",
    "\n",
    "spark_df = spark_df.withColumn(\"DelayCategory\", \n",
    "                   when(col(\"Delay\") <= 0, \"No Delay\")\n",
    "                   .when((col(\"Delay\") > 0) & (col(\"Delay\") <= 10), \"Short Delay\")\n",
    "                   .when((col(\"Delay\") > 10) & (col(\"Delay\") <= 20), \"Medium Delay\")\n",
    "                   .otherwise(\"Long Delay\"))\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfe2968f-2946-4db9-ae41-de14ed0cd8fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "\n",
    "average_passengers = spark_df.select(avg(\"Passengers\")).first()[0]\n",
    "\n",
    "# Identifier les heures de pointe et heures hors pointe en fonction du nombre de passagers :\n",
    "\n",
    "spark_df = spark_df.withColumn(\"HeureDePointe\", when(col(\"Passengers\") > average_passengers, \"peak\").otherwise(\"off-peak\"))\n",
    "\n",
    "# Afficher le DataFrame avec les heures de pointe identifiées :\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dabe3c76-2076-40da-9d82-f9b33ee4216e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "result_df = spark_df.groupBy(\"Route\").agg(\n",
    "    avg(\"Delay\").alias(\"RetardMoyen\"),\n",
    "    avg(\"Passengers\").alias(\"NombrePassagersMoyen\"),\n",
    "    count(\"*\").alias(\"NombreTotalVoyages\")\n",
    ")\n",
    "\n",
    "#Afficher le DataFrame résultant :\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08f6f103-c07d-4b00-b9cc-d90c55d3d5f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ETL_public_transport_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
